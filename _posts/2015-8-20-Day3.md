---
layout: post
comments: true
title: Day3 - Recurrent Neural Networks
excerpt: This excise will introduce recurrent neural networks
date: 2015-08-23T11:00:00.000Z
mathjax: true
published: true
---

##### Course Material 
  * Exercise: [Github Repo](https://github.com/DTU-deeplearning/day3-RNN)
  * Slides: Will be upladed
  * Suggested Readings: Alex Graves, [Supervised Sequence Labelling with Recurrent Neural Networks](http://www.cs.toronto.edu/~graves/preprint.pdf), Chapters 1-4,


##### Additional Material 

  * **[Sequence to Sequence Learning with Neural Networks](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)**: Original Encoder-Decoder RNN paper.
  * **[Neural Machine Translation by Jointly Learning to Align and Translate](http://arxiv.org/pdf/1409.0473v6.pdf)**: Original RNN attention paper.
  * **[Show, Attend and Tell: Neural Image Caption Generation with Visual Attention](http://jmlr.org/proceedings/papers/v37/xuc15.pdf)**: Visual Attention.
  * **[The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)**: Very nice blog post by Andreiy Karpathy describing character-RNNs implemented in Torch.
  * **[CS224d: Deep Learning for Natural Language Processing](http://cs224d.stanford.edu/syllabus.html)**: Stanford course on Neural networks for natural language processing by Richard Socher